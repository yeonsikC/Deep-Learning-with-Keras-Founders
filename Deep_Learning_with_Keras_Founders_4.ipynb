{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deep-Learning-with-Keras-Founders - 4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMg/AQTXt4xRjOnw5vIEibU",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeonsikC/Deep-Learning-with-Keras-Founders/blob/master/Deep_Learning_with_Keras_Founders_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiZzrSvmvPx7",
        "colab_type": "text"
      },
      "source": [
        "# 머신러닝"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w2b2xHIVvyTu",
        "colab_type": "text"
      },
      "source": [
        "## 4. 1. 여러 검증 방법들"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6znqDgdcv2Ix",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#홀드아웃\n",
        "num_validation_samples = 10000\n",
        "\n",
        "np.random.shuffle(data)\n",
        "\n",
        "validation_data = data[:num_validation_samples]\n",
        "data = data[num_validation_samples:]\n",
        "\n",
        "trainin_data = data[:]\n",
        "\n",
        "model = get_model()\n",
        "model.train(training_data)\n",
        "validation_score = model.evaluate(validation_data)\n",
        "\n",
        "# 여기에서 모델을 튜닝하고,\n",
        "# 다시 훈련하고, 평가하고, 또 다시 튜닝하고 ...\n",
        "\n",
        "# 하이퍼파라미터 튜닝이 끝나면 테스트 데이터를 제외한 모든 데이터를 통해 모델을 다시 훈련시킨다.\n",
        "model = get_model()\n",
        "model.train(np.concateenate([trainin_data,\n",
        "                             validation_data]))\n",
        "test_score = model.evaluate(test_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UvYGJOSK72qG",
        "colab": {}
      },
      "source": [
        "#K-Fold\n",
        "k = 4\n",
        "num_validation_samples = len(data) // k\n",
        " \n",
        "np.random.shuffle(data)\n",
        "\n",
        "validation_scores = []\n",
        "for fold in range(k):\n",
        "  validation_data = data[num_validation_samples * fold:\n",
        "                         num_validation_samples * (fold + 1)]\n",
        "  training_data = data[:num_validation_samples * fold] +\n",
        "                  data[num_validation_samples * (fold + 1):]\n",
        "\n",
        "  model = get_model()\n",
        "  model.train(training_data)\n",
        "  validation_score = model.evaluate(validation_data)\n",
        "  validation_scores.append(validation_score)\n",
        "\n",
        "  validation_score = np.average(validation_scores) # 검증 점수 : k개 폴드의 검증 점수 평균\n",
        "\n",
        "  model = get_model()\n",
        "  model.train(data)\n",
        "  test_score = model.evaluate(test_data)\n",
        "\n",
        "  #해당 검증은 사이킷런의 cross_validate() 함수를 이용하면 된다.\n",
        "  #다만, 케라스와 호환되도록 KerasClassifier나 KerasRegressor 클래스로 모델을 감싸야 합니다."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I8DeN1A8FBI",
        "colab_type": "text"
      },
      "source": [
        "##4. 2. 데이터 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i5C-g0529L2G",
        "colab_type": "text"
      },
      "source": [
        "- 벡터화 : 신경망에서 모든 입력과 타깃은 부동 소수 데이터로 이루어진 텐서여야 한다.\n",
        "- 정규화 : 작은 값을 취해야 함(대부분 0~1), 균일해야 한다.\n",
        "  * 각 특성별로 N(0,1)을 따라야 좋다. -> x-=x.mean(axis=0); x/= x.std(axis=0)\n",
        "- 특성공학 : ex) 시계바늘 등 미리 하드코딩 된 정보를 모델에 주입시키면 적은 데이터로 더 좋은 효율을 낼 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t3Po7Vc2Bu1v",
        "colab_type": "text"
      },
      "source": [
        "##4. 3. 과대적합과 과소적합 / 네트워크 크기 축소\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zncDLn4rBzt5",
        "colab_type": "code",
        "outputId": "a6fcba3c-0eb9-4527-c2cd-f25e474a386d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "#영화 리뷰 분류 모델, 하이퍼파라미터 및 네트워크 조절\n",
        "from keras import models\n",
        "from keras import layers\n",
        "\n",
        "#원본모델\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFAfOChYGObq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#작은 용량의 모델\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(6, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(6, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXv1auz5GeJj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#큰 용량의 모델\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(1024, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(1024, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78_FmujiG8Pb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#가중치 규제 L1 & L2\n",
        "from keras import regularizers\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                       activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dense(16, kernel_regularizer=regularizers.l2(0.001),\n",
        "                       activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "#l2(0.001)은 가중치 행렬의 모든 원소를 제곱하고 0.001을 곱하여 네트워크의 전체 손실에 더해 진다는 의미이다.\n",
        "#이 페널티 항은 훈련할 때만 추가된다. (과대적합에 더 견딘다.)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "221XHc2xL1Fq",
        "colab_type": "code",
        "outputId": "ce3846e3-835d-4e71-d5d0-f48ae8af858a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "#가중치 규제 선택 가능\n",
        "from keras import regularizers\n",
        "\n",
        "regularizers.l1(0.001) # L1 규제\n",
        "regularizers.l1_l2(l1=0.001, l2=0.001) #L1과 L2 규제 병행"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.regularizers.L1L2 at 0x7f36bd7a1c50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aVKEOkpJMLms",
        "colab_type": "code",
        "outputId": "18415153-dc56-481b-a9ad-634e4cd92bf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "#Dropout\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(16, activation='relu', input_shape=(10000,)))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(16, activation='relu'))\n",
        "model.add(layers.Dropout(0.5))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YOdnTaYbP81a",
        "colab_type": "text"
      },
      "source": [
        "- 신경망에서 과대적합을 방지하기 위한 방법\n",
        "  * 훈련 데이터를 더 늘린다.\n",
        "  * 네트워크의 용량을 감소시킨다. (은닉층, 유닛 수 등)\n",
        "  * 가중치 규제를 추가한다.\n",
        "  * 드롭아웃을 추가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VkpriQfQPBO",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}